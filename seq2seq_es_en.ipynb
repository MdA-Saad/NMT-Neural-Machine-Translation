{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1oICDZtXRKgFkKgh6EgznERVGajbo2WH2",
      "authorship_tag": "ABX9TyOBeZ9Rh4tfg9t5sRzpC3N8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MdA-Saad/NMT-Neural-Machine-Translation-/blob/main/seq2seq_es_en.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from io import open\n",
        "import unicodedata\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence,pad_sequence\n",
        "from torch.optim import Adam\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "ZxmzcwfsGDIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def load_parallel_data(en_path, es_path, num_samples=5):\n",
        "    \"\"\"\n",
        "    Reads English and Spanish files and pairs them up.\n",
        "    \"\"\"\n",
        "    # Check if files exist\n",
        "    if not os.path.exists(en_path) or not os.path.exists(es_path):\n",
        "        return \"Error: One or both files were not found. Check your file paths!\"\n",
        "\n",
        "    parallel_data = []\n",
        "\n",
        "    # Using 'zip' ensures we only pair lines that have a match in both files\n",
        "    with open(en_path, 'r', encoding='utf-8') as en_file, \\\n",
        "         open(es_path, 'r', encoding='utf-8') as es_file:\n",
        "\n",
        "        for en_line, es_line in zip(en_file, es_file):\n",
        "            # .strip() removes the newline character (\\n)\n",
        "            en_sent = en_line.strip()\n",
        "            es_sent = es_line.strip()\n",
        "\n",
        "            # Skip empty lines if any\n",
        "            if en_sent and es_sent:\n",
        "                parallel_data.append({\"en\": en_sent, \"es\": es_sent})\n",
        "\n",
        "    print(f\"Successfully loaded {len(parallel_data)} parallel sentences.\")\n",
        "\n",
        "    # Show a few examples\n",
        "    print(\"\\n--- Examples ---\")\n",
        "    for i in range(min(num_samples, len(parallel_data))):\n",
        "        print(f\"[{i}] EN: {parallel_data[i]['en']}\")\n",
        "        print(f\"    ES: {parallel_data[i]['es']}\\n\")\n",
        "\n",
        "    return parallel_data\n",
        "\n",
        "# Replace these with your actual filenames\n",
        "EN_FILE = \"/content/drive/MyDrive/Colab Notebooks/eng2esp_transformer/es-en/TED2020.en-es.en\"\n",
        "ES_FILE = \"/content/drive/MyDrive/Colab Notebooks/eng2esp_transformer/es-en/TED2020.en-es.es\"\n",
        "\n",
        "data = load_parallel_data(EN_FILE, ES_FILE)"
      ],
      "metadata": {
        "id": "LD9O69ojlFHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VOCABULARY CLASS\n",
        "class Vocab:\n",
        "    SPECIAL_TOKENS = {\n",
        "        \"<PAD>\": 0,\n",
        "        \"<SOS>\": 1,\n",
        "        \"<EOS>\": 2,\n",
        "        \"<UNK>\": 3,\n",
        "    }\n",
        "\n",
        "    def __init__(self, language: str):\n",
        "        self.language = language\n",
        "        self.word2index = {}\n",
        "        self.index2word = {}\n",
        "        self.n_words = 0\n",
        "\n",
        "        # Initialize with special tokens\n",
        "        for token, idx in self.SPECIAL_TOKENS.items():\n",
        "            self.word2index[token] = idx\n",
        "            self.index2word[idx] = token\n",
        "        self.n_words = len(self.SPECIAL_TOKENS)\n",
        "\n",
        "    def normalize_string(self, string: str) -> str:\n",
        "        \"\"\"Normalize text for the given language\"\"\"\n",
        "        string = string.lower().strip()\n",
        "        # Add spaces around punctuation\n",
        "        string = re.sub(r\"([.!?¿¡])\", r\" \\1 \", string)\n",
        "        # Keep language-specific characters\n",
        "        if self.language == \"spanish\":\n",
        "            string = re.sub(r\"[^a-záéíóúüñ.!?¿¡]+\", r\" \", string)\n",
        "        else:\n",
        "            string = re.sub(r\"[^a-z.!?]+\", r\" \", string)\n",
        "        return re.sub(r\"\\s+\", \" \", string).strip()\n",
        "\n",
        "    def add_sentence(self, sentence: str):\n",
        "        \"\"\"Add all words in a sentence to vocabulary\"\"\"\n",
        "        for word in self.normalize_string(sentence).split():\n",
        "            if word not in self.word2index:\n",
        "                self.word2index[word] = self.n_words\n",
        "                self.index2word[self.n_words] = word\n",
        "                self.n_words += 1\n",
        "\n",
        "    def numericalize(self, sentence: str, max_len: Optional[int] = None) -> List[int]:\n",
        "        \"\"\"Convert sentence to list of token indices\"\"\"\n",
        "        tokens = self.normalize_string(sentence).split()\n",
        "        if max_len:\n",
        "            tokens = tokens[:max_len-2]  # Reserve space for SOS and EOS\n",
        "\n",
        "        ids = [self.word2index[\"<SOS>\"]]\n",
        "        ids.extend(self.word2index.get(t, self.word2index[\"<UNK>\"]) for t in tokens)\n",
        "        ids.append(self.word2index[\"<EOS>\"])\n",
        "        return ids\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_words"
      ],
      "metadata": {
        "id": "jnE8ztjalSpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DATASET CLASS\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, source_sentences: List[str], target_sentences: List[str],\n",
        "                 source_vocab: Vocab, target_vocab: Vocab, max_len: int = 50):\n",
        "        assert len(source_sentences) == len(target_sentences), \"Source and target must have same length\"\n",
        "        self.source_sentences = source_sentences\n",
        "        self.target_sentences = target_sentences\n",
        "        self.source_vocab = source_vocab\n",
        "        self.target_vocab = target_vocab\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.source_sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        source = self.source_vocab.numericalize(self.source_sentences[idx], self.max_len)\n",
        "        target = self.target_vocab.numericalize(self.target_sentences[idx], self.max_len)\n",
        "        return torch.tensor(source), torch.tensor(target)\n",
        "\n",
        "def collate_fn(batch, source_pad_id=0, target_pad_id=0):\n",
        "    \"\"\"Custom collate function for padding sequences\"\"\"\n",
        "    source_seqs, target_seqs = zip(*batch)\n",
        "\n",
        "    source_padded = pad_sequence(source_seqs, batch_first=True, padding_value=source_pad_id)\n",
        "    target_padded = pad_sequence(target_seqs, batch_first=True, padding_value=target_pad_id)\n",
        "\n",
        "    source_lengths = torch.tensor([len(seq) for seq in source_seqs], dtype=torch.long)\n",
        "    target_lengths = torch.tensor([len(seq) for seq in target_seqs], dtype=torch.long)\n",
        "\n",
        "    # Sort by source lengths in descending order for pack_padded_sequence\n",
        "    source_lengths, perm_idx = source_lengths.sort(0, descending=True)\n",
        "    source_padded = source_padded[perm_idx]\n",
        "    target_padded = target_padded[perm_idx]\n",
        "    target_lengths = target_lengths[perm_idx]\n",
        "\n",
        "    return {\n",
        "        \"source_padded\": source_padded,\n",
        "        \"target_padded\": target_padded,\n",
        "        \"source_lengths\": source_lengths,\n",
        "        \"target_lengths\": target_lengths,\n",
        "        \"perm_idx\": perm_idx  # To restore original order after decoding\n",
        "    }\n"
      ],
      "metadata": {
        "id": "xmNulSkIlZ_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ENCODER\n",
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size, embed_size=None, dropout_p=0.1):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        embed_size = embed_size or hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
        "        self.gru = nn.GRU(embed_size, hidden_size, batch_first=True, bidirectional=True)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.fc = nn.Linear(hidden_size * 2, hidden_size)  # For combining bidirectional states\n",
        "\n",
        "    def forward(self, source, source_lengths):\n",
        "        embedded = self.dropout(self.embedding(source))\n",
        "\n",
        "        # Pack padded sequences\n",
        "        packed = pack_padded_sequence(embedded, source_lengths.cpu(), batch_first=True, enforce_sorted=True)\n",
        "        packed_output, hidden = self.gru(packed)\n",
        "\n",
        "        # Unpack sequences\n",
        "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
        "\n",
        "        # Combine bidirectional hidden states\n",
        "        # hidden shape: (num_layers * num_directions, batch, hidden_size)\n",
        "        hidden = torch.cat((hidden[-2], hidden[-1]), dim=1)  # FIXED: missing comma and parentheses\n",
        "        hidden = torch.tanh(self.fc(hidden))\n",
        "        hidden = hidden.unsqueeze(0)  # (1, batch, hidden_size)\n",
        "\n",
        "        return output, hidden"
      ],
      "metadata": {
        "id": "huuc9HbJlfqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ATTENTION (FIXED)\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super().__init__()\n",
        "        self.Wa = nn.Linear(hidden_size, hidden_size, bias=False)\n",
        "        self.Ua = nn.Linear(hidden_size * 2, hidden_size, bias=False)\n",
        "        self.va = nn.Parameter(torch.rand(hidden_size))\n",
        "\n",
        "    def forward(self, decoder_hidden, encoder_outputs, source_mask=None):\n",
        "        \"\"\"\n",
        "        decoder_hidden: (1, batch, hidden_size)\n",
        "        encoder_outputs: (batch, seq_len, hidden_size*2)\n",
        "        source_mask: (batch, 1, seq_len) - True for valid positions\n",
        "        \"\"\"\n",
        "        # decoder_hidden: (batch, hidden_size)\n",
        "        dec_hid = decoder_hidden.squeeze(0)\n",
        "\n",
        "        # Transform decoder hidden state: (batch, 1, hidden_size)\n",
        "        dec_transformed = self.Wa(dec_hid).unsqueeze(1)\n",
        "\n",
        "        # Transform encoder outputs: (batch, seq_len, hidden_size)\n",
        "        enc_transformed = self.Ua(encoder_outputs)\n",
        "\n",
        "        # Calculate attention energies: (batch, seq_len, hidden_size)\n",
        "        energy = torch.tanh(dec_transformed + enc_transformed)\n",
        "\n",
        "        # Calculate scores: (batch, seq_len)\n",
        "        scores = torch.matmul(energy, self.va.unsqueeze(1)).squeeze(2)\n",
        "\n",
        "        # Apply mask if provided\n",
        "        if source_mask is not None:\n",
        "            scores = scores.masked_fill(~source_mask.squeeze(1), -1e10)\n",
        "\n",
        "        # Calculate attention weights: (batch, 1, seq_len)\n",
        "        attn_weights = F.softmax(scores, dim=1).unsqueeze(1)\n",
        "\n",
        "        # Calculate context vector: (batch, hidden_size*2)\n",
        "        context = torch.bmm(attn_weights, encoder_outputs).squeeze(1)\n",
        "\n",
        "        return context, attn_weights.squeeze(1)"
      ],
      "metadata": {
        "id": "WEbUGiNTlkGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DECODER (FIXED)\n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size, embed_size=None, dropout_p=0.1):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        embed_size = embed_size or hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
        "        self.attention = Attention(hidden_size)\n",
        "        self.gru = nn.GRU(embed_size + hidden_size * 2, hidden_size, batch_first=True)\n",
        "        self.fc_out = nn.Linear(hidden_size + hidden_size * 2, vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, target, encoder_outputs, hidden, source_mask=None, teacher_forcing_ratio=0.5):\n",
        "        \"\"\"\n",
        "        target: (batch, tgt_len)\n",
        "        encoder_outputs: (batch, src_len, hidden_size*2)\n",
        "        hidden: (1, batch, hidden_size)\n",
        "        \"\"\"\n",
        "        batch_size = target.size(0)\n",
        "        target_len = target.size(1)\n",
        "        vocab_size = self.fc_out.out_features\n",
        "\n",
        "        # Tensor to store decoder outputs\n",
        "        outputs = torch.zeros(batch_size, target_len, vocab_size).to(target.device)\n",
        "\n",
        "        # First input token is SOS\n",
        "        input_token = target[:, 0]\n",
        "\n",
        "        for t in range(1, target_len):\n",
        "            # Embed input token\n",
        "            embedded = self.dropout(self.embedding(input_token)).unsqueeze(1)  # (batch, 1, embed_size)\n",
        "\n",
        "            # Calculate attention context\n",
        "            context, attn_weights = self.attention(hidden, encoder_outputs, source_mask)\n",
        "            context = context.unsqueeze(1)  # (batch, 1, hidden_size*2)\n",
        "\n",
        "            # Combine embedded input and context\n",
        "            rnn_input = torch.cat((embedded, context), dim=2)  # (batch, 1, embed_size + hidden_size*2)\n",
        "\n",
        "            # Pass through GRU\n",
        "            output, hidden = self.gru(rnn_input, hidden)\n",
        "\n",
        "            # Combine output and context for prediction\n",
        "            output = output.squeeze(1)  # (batch, hidden_size)\n",
        "            context = context.squeeze(1)  # (batch, hidden_size*2)\n",
        "\n",
        "            pred = self.fc_out(torch.cat((output, context), dim=1))  # (batch, vocab_size)\n",
        "            outputs[:, t, :] = pred\n",
        "\n",
        "            # Teacher forcing\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top1 = pred.argmax(1)\n",
        "\n",
        "            # Next input is current target token (teacher forcing) or predicted token\n",
        "            input_token = target[:, t] if teacher_force else top1\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "t6kZdjWulo63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UTILITY FUNCTIONS\n",
        "def create_mask(source, pad_idx=0):\n",
        "    \"\"\"Create mask for source sequences\"\"\"\n",
        "    return (source != pad_idx).unsqueeze(1)  # (batch, 1, seq_len)\n",
        "\n",
        "def translate_sentence(encoder, decoder, sentence, src_vocab, tgt_vocab, device, max_len=50):\n",
        "    \"\"\"Translate a single sentence\"\"\"\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "\n",
        "    # Tokenize and numericalize input sentence\n",
        "    tokens = src_vocab.numericalize(sentence, max_len)\n",
        "    src_tensor = torch.LongTensor(tokens).unsqueeze(0).to(device)\n",
        "    src_len = torch.LongTensor([len(tokens)]).to(device)\n",
        "\n",
        "    # Encode source sentence\n",
        "    with torch.no_grad():\n",
        "        encoder_outputs, hidden = encoder(src_tensor, src_len)\n",
        "\n",
        "    # Prepare target sequence\n",
        "    trg_indexes = [tgt_vocab.word2index[\"<SOS>\"]]\n",
        "\n",
        "    # Generate translation\n",
        "    for _ in range(max_len):\n",
        "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Get context vector using attention\n",
        "            context, _ = decoder.attention(hidden, encoder_outputs)\n",
        "\n",
        "            # Prepare decoder input\n",
        "            embedded = decoder.dropout(decoder.embedding(trg_tensor.unsqueeze(0)))\n",
        "            rnn_input = torch.cat((embedded, context.unsqueeze(1)), dim=2)\n",
        "\n",
        "            output, hidden = decoder.gru(rnn_input, hidden)\n",
        "            output = output.squeeze(1)\n",
        "            context = context.squeeze(0)\n",
        "\n",
        "            pred = decoder.fc_out(torch.cat((output, context.unsqueeze(0)), dim=1))\n",
        "            pred_token = pred.argmax(1).item()\n",
        "\n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == tgt_vocab.word2index[\"<EOS>\"]:\n",
        "            break\n",
        "\n",
        "    # Convert indexes to tokens\n",
        "    trg_tokens = [tgt_vocab.index2word[i] for i in trg_indexes]\n",
        "\n",
        "    # Remove special tokens\n",
        "    translation = ' '.join(trg_tokens[1:-1])  # Remove SOS and EOS\n",
        "\n",
        "    return translation\n"
      ],
      "metadata": {
        "id": "P8b8Re0iltIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING FUNCTIONS\n",
        "def train_epoch(encoder, decoder, dataloader, optimizer, criterion, clip=1.0, teacher_forcing_ratio=0.5, device='cpu'):\n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in dataloader:\n",
        "        source = batch[\"source_padded\"].to(device)\n",
        "        target = batch[\"target_padded\"].to(device)\n",
        "        source_lengths = batch[\"source_lengths\"].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        encoder_outputs, hidden = encoder(source, source_lengths)\n",
        "        source_mask = create_mask(source).to(device)\n",
        "        outputs = decoder(target, encoder_outputs, hidden, source_mask, teacher_forcing_ratio)\n",
        "\n",
        "        # Calculate loss (ignore padding tokens)\n",
        "        output_dim = outputs.shape[-1]\n",
        "        outputs = outputs[:, 1:].reshape(-1, output_dim)  # Skip SOS token\n",
        "        target = target[:, 1:].reshape(-1)  # Skip SOS token\n",
        "\n",
        "        loss = criterion(outputs, target)\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip gradients\n",
        "        torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
        "        torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
        "\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ],
      "metadata": {
        "id": "rUhiHzGcl0e6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference\n",
        "@torch.no_grad()\n",
        "def evaluate(encoder, decoder, dataloader, criterion, device='cpu'):\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in dataloader:\n",
        "        source = batch[\"source_padded\"].to(device)\n",
        "        target = batch[\"target_padded\"].to(device)\n",
        "        source_lengths = batch[\"source_lengths\"].to(device)\n",
        "\n",
        "        encoder_outputs, hidden = encoder(source, source_lengths)\n",
        "        source_mask = create_mask(source).to(device)\n",
        "        outputs = decoder(target, encoder_outputs, hidden, source_mask, teacher_forcing_ratio=0.0)  # Turn off teacher forcing\n",
        "\n",
        "        output_dim = outputs.shape[-1]\n",
        "        outputs = outputs[:, 1:].reshape(-1, output_dim)\n",
        "        target = target[:, 1:].reshape(-1)\n",
        "\n",
        "        loss = criterion(outputs, target)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ],
      "metadata": {
        "id": "wn87vb_Wl20u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING LOOP\n",
        "def main():\n",
        "    # Set device\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Prepare data\n",
        "    english_sentences = df['english'].tolist()\n",
        "    spanish_sentences = df['spanish'].tolist()\n",
        "\n",
        "    # Create train/val split\n",
        "    train_eng, val_eng, train_spa, val_spa = train_test_split(\n",
        "        english_sentences, spanish_sentences, test_size=0.1, random_state=42\n",
        "    )\n",
        "\n",
        "    print(f\"Training samples: {len(train_eng)}\")\n",
        "    print(f\"Validation samples: {len(val_eng)}\")\n",
        "\n",
        "    # Build vocabularies\n",
        "    english_vocab = Vocab(\"english\")\n",
        "    spanish_vocab = Vocab(\"spanish\")\n",
        "\n",
        "    # Add sentences to vocabularies\n",
        "    for eng, spa in zip(train_eng, train_spa):\n",
        "        english_vocab.add_sentence(eng)\n",
        "        spanish_vocab.add_sentence(spa)\n",
        "\n",
        "    print(f\"English vocab size: {len(english_vocab)}\")\n",
        "    print(f\"Spanish vocab size: {len(spanish_vocab)}\")\n",
        "\n",
        "    # Create datasets\n",
        "    MAX_LEN = 30\n",
        "    train_dataset = TranslationDataset(train_eng, train_spa, english_vocab, spanish_vocab, max_len=MAX_LEN)\n",
        "    val_dataset = TranslationDataset(val_eng, val_spa, english_vocab, spanish_vocab, max_len=MAX_LEN)\n",
        "\n",
        "    # Create dataloaders\n",
        "    BATCH_SIZE = 64\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        collate_fn=lambda b: collate_fn(\n",
        "            b,\n",
        "            source_pad_id=english_vocab.word2index[\"<PAD>\"],\n",
        "            target_pad_id=spanish_vocab.word2index[\"<PAD>\"]\n",
        "        )\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        collate_fn=lambda b: collate_fn(\n",
        "            b,\n",
        "            source_pad_id=english_vocab.word2index[\"<PAD>\"],\n",
        "            target_pad_id=spanish_vocab.word2index[\"<PAD>\"]\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Initialize model\n",
        "    HIDDEN_SIZE = 256\n",
        "    encoder = EncoderRNN(len(english_vocab), HIDDEN_SIZE).to(device)\n",
        "    decoder = DecoderRNN(len(spanish_vocab), HIDDEN_SIZE).to(device)\n",
        "\n",
        "    # Optimizer and loss function\n",
        "    optimizer = Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=spanish_vocab.word2index[\"<PAD>\"])\n",
        "\n",
        "    # Training loop\n",
        "    N_EPOCHS = 10\n",
        "    best_valid_loss = float('inf')\n",
        "\n",
        "    for epoch in range(N_EPOCHS):\n",
        "        train_loss = train_epoch(\n",
        "            encoder, decoder, train_loader, optimizer, criterion,\n",
        "            clip=1.0, teacher_forcing_ratio=0.5, device=device\n",
        "        )\n",
        "        valid_loss = evaluate(encoder, decoder, val_loader, criterion, device=device)\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}/{N_EPOCHS} | Train Loss: {train_loss:.4f} | Val Loss: {valid_loss:.4f}\")\n",
        "\n",
        "        # Save best model\n",
        "        if valid_loss < best_valid_loss:\n",
        "            best_valid_loss = valid_loss\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'encoder_state_dict': encoder.state_dict(),\n",
        "                'decoder_state_dict': decoder.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'train_loss': train_loss,\n",
        "                'valid_loss': valid_loss,\n",
        "                'english_vocab': english_vocab,\n",
        "                'spanish_vocab': spanish_vocab,\n",
        "            }, \"best_translation_model.pt\")\n",
        "            print(f\"Saved new best model with validation loss: {valid_loss:.4f}\")\n",
        "\n",
        "    print(\"Training complete!\")\n",
        "\n",
        "    # Test translation with a few examples\n",
        "    print(\"\\nTranslation Examples:\")\n",
        "    test_sentences = [\n",
        "        \"Hello, how are you?\",\n",
        "        \"I love programming.\",\n",
        "        \"What is your name?\",\n",
        "        \"The weather is nice today.\"\n",
        "    ]\n",
        "\n",
        "    for sentence in test_sentences:\n",
        "        translation = translate_sentence(\n",
        "            encoder, decoder, sentence, english_vocab, spanish_vocab, device, max_len=30\n",
        "        )\n",
        "        print(f\"EN: {sentence}\")\n",
        "        print(f\"ES: {translation}\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "1I5zb0vtl8fg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluation\n",
        "import sacrebleu\n",
        "from sacrebleu.metrics import BLEU, CHRF, TER\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "import nltk\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Download required NLTK data once\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('omw-1.4', quiet=True)\n",
        "\n",
        "class MTEvaluator:\n",
        "    \"\"\"Comprehensive MT evaluation suite\"\"\"\n",
        "\n",
        "    def __init__(self, target_language='es'):\n",
        "        self.bleu = BLEU()\n",
        "        self.chrf = CHRF(word_order=2)  # chrF++\n",
        "        self.ter = TER()\n",
        "        self.target_lang = target_language\n",
        "\n",
        "    def normalize_text(self, text):\n",
        "        \"\"\"Light normalization for fair comparison\"\"\"\n",
        "        text = text.strip().lower()\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        return text\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def generate_translations(self, encoder, decoder, dataloader,\n",
        "                             src_vocab, tgt_vocab, device, max_len=50):\n",
        "        \"\"\"Generate translations for entire dataset\"\"\"\n",
        "        encoder.eval()\n",
        "        decoder.eval()\n",
        "\n",
        "        sources, references, hypotheses = [], [], []\n",
        "\n",
        "        for batch in tqdm(dataloader, desc=\"Generating translations\"):\n",
        "            source = batch[\"source_padded\"].to(device)\n",
        "            target = batch[\"target_padded\"].to(device)\n",
        "            source_lengths = batch[\"source_lengths\"].to(device)\n",
        "            perm_idx = batch[\"perm_idx\"]\n",
        "\n",
        "            # Reverse sorting to restore original order\n",
        "            inv_perm = torch.argsort(perm_idx)\n",
        "\n",
        "            # Encode\n",
        "            encoder_outputs, hidden = encoder(source, source_lengths)\n",
        "            source_mask = create_mask(source).to(device)\n",
        "\n",
        "            # Greedy decoding\n",
        "            batch_size = source.size(0)\n",
        "            trg_indexes = [[tgt_vocab.word2index[\"<SOS>\"]] * batch_size]\n",
        "            hidden_states = hidden\n",
        "\n",
        "            # Track which sequences are finished\n",
        "            unfinished = torch.ones(batch_size, dtype=torch.bool).to(device)\n",
        "\n",
        "            for t in range(1, max_len):\n",
        "                # Get last predicted tokens\n",
        "                input_tokens = torch.tensor([trg_indexes[-1][i] for i in range(batch_size)]).to(device)\n",
        "\n",
        "                # Embedding + attention\n",
        "                embedded = decoder.embedding(input_tokens.unsqueeze(1))\n",
        "                context, _ = decoder.attention(hidden_states, encoder_outputs, source_mask)\n",
        "                rnn_input = torch.cat((embedded, context.unsqueeze(1)), dim=2)\n",
        "\n",
        "                output, hidden_states = decoder.gru(rnn_input, hidden_states)\n",
        "                output = output.squeeze(1)\n",
        "                context = context\n",
        "\n",
        "                pred = decoder.fc_out(torch.cat((output, context), dim=1))\n",
        "                pred_tokens = pred.argmax(1)\n",
        "\n",
        "                # Stop predicting for finished sequences\n",
        "                pred_tokens[~unfinished] = tgt_vocab.word2index[\"<PAD>\"]\n",
        "                unfinished &= (pred_tokens != tgt_vocab.word2index[\"<EOS>\"])\n",
        "\n",
        "                trg_indexes.append(pred_tokens.cpu().tolist())\n",
        "\n",
        "                if not unfinished.any():\n",
        "                    break\n",
        "\n",
        "            # Convert indexes to text\n",
        "            for i in range(batch_size):\n",
        "                # Get hypothesis\n",
        "                hyp_ids = [trg_indexes[t][i] for t in range(len(trg_indexes))\n",
        "                          if trg_indexes[t][i] not in [tgt_vocab.word2index[\"<SOS>\"],\n",
        "                                                      tgt_vocab.word2index[\"<EOS>\"],\n",
        "                                                      tgt_vocab.word2index[\"<PAD>\"]]]\n",
        "                hyp = ' '.join([tgt_vocab.index2word.get(idx, '<UNK>') for idx in hyp_ids])\n",
        "\n",
        "                # Get reference (skip special tokens)\n",
        "                ref_ids = target[inv_perm[i]][1:]  # Skip SOS\n",
        "                ref_ids = [idx.item() for idx in ref_ids\n",
        "                          if idx.item() not in [tgt_vocab.word2index[\"<SOS>\"],\n",
        "                                               tgt_vocab.word2index[\"<EOS>\"],\n",
        "                                               tgt_vocab.word2index[\"<PAD>\"]]]\n",
        "                ref = ' '.join([tgt_vocab.index2word.get(idx, '<UNK>') for idx in ref_ids])\n",
        "\n",
        "                # Get source for debugging\n",
        "                src_ids = source[inv_perm[i]]\n",
        "                src_ids = [idx.item() for idx in src_ids\n",
        "                          if idx.item() not in [src_vocab.word2index[\"<PAD>\"]]]\n",
        "                src = ' '.join([src_vocab.index2word.get(idx, '<UNK>') for idx in src_ids])\n",
        "\n",
        "                hypotheses.append(hyp)\n",
        "                references.append(ref)\n",
        "                sources.append(src)\n",
        "\n",
        "        return sources, references, hypotheses\n",
        "\n",
        "    def compute_metrics(self, hypotheses, references):\n",
        "        \"\"\"Compute multiple MT metrics\"\"\"\n",
        "        # Ensure references is list of lists (multiple references per hypothesis)\n",
        "        if isinstance(references[0], str):\n",
        "            references = [[ref] for ref in references]\n",
        "\n",
        "        # BLEU (sacrebleu handles tokenization properly)\n",
        "        bleu = sacrebleu.corpus_bleu(hypotheses, references,\n",
        "                                    tokenize='intl' if self.target_lang == 'es' else '13a')\n",
        "\n",
        "        # chrF++ (better for Spanish morphology)\n",
        "        chrf = sacrebleu.corpus_chrf(hypotheses, references, word_order=2)\n",
        "\n",
        "        # TER\n",
        "        ter = sacrebleu.corpus_ter(hypotheses, references)\n",
        "\n",
        "        # METEOR (requires NLTK)\n",
        "        meteor_scores = [\n",
        "            meteor_score([ref[0].split() for ref in references[i]], hyp.split())\n",
        "            for i, hyp in enumerate(hypotheses)\n",
        "        ]\n",
        "        meteor_avg = np.mean(meteor_scores)\n",
        "\n",
        "        return {\n",
        "            'BLEU': bleu.score,\n",
        "            'chrF++': chrf.score,\n",
        "            'TER': ter.score,\n",
        "            'METEOR': meteor_avg * 100,  # Convert to percentage\n",
        "            'n_samples': len(hypotheses)\n",
        "        }\n",
        "\n",
        "    def detailed_report(self, sources, references, hypotheses, n_samples=5):\n",
        "        \"\"\"Print detailed examples with metrics\"\"\"\n",
        "        metrics = self.compute_metrics(hypotheses, references)\n",
        "\n",
        "        print(\"=\"*80)\n",
        "        print(\"TRANSLATION EVALUATION REPORT\")\n",
        "        print(\"=\"*80)\n",
        "        print(f\"Total samples: {metrics['n_samples']}\")\n",
        "        print(f\"BLEU:    {metrics['BLEU']:.2f}\")\n",
        "        print(f\"chrF++:  {metrics['chrF++']:.2f}  ← Best for Spanish morphology\")\n",
        "        print(f\"TER:     {metrics['TER']:.2f} (lower is better)\")\n",
        "        print(f\"METEOR:  {metrics['METEOR']:.2f}\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Show examples\n",
        "        print(\"\\nEXAMPLE TRANSLATIONS:\\n\")\n",
        "        for i in range(min(n_samples, len(sources))):\n",
        "            print(f\"Source (EN):      {sources[i]}\")\n",
        "            print(f\"Reference (ES):   {references[i][0] if isinstance(references[i], list) else references[i]}\")\n",
        "            print(f\"Hypothesis (ES):  {hypotheses[i]}\")\n",
        "            print(\"-\"*80)\n",
        "\n",
        "        return metrics\n",
        "\n",
        "# Usage example:\n",
        "def evaluate_model(encoder, decoder, val_loader, src_vocab, tgt_vocab, device):\n",
        "    evaluator = MTEvaluator(target_language='es')\n",
        "\n",
        "    # Generate translations\n",
        "    sources, references, hypotheses = evaluator.generate_translations(\n",
        "        encoder, decoder, val_loader, src_vocab, tgt_vocab, device, max_len=40\n",
        "    )\n",
        "\n",
        "    # Compute metrics\n",
        "    metrics = evaluator.compute_metrics(hypotheses, references)\n",
        "\n",
        "    # Print detailed report\n",
        "    evaluator.detailed_report(sources, references, hypotheses, n_samples=10)\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "BsNufDo2my8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Benchmarking\n",
        "# After training, evaluate on WMT test set\n",
        "import datasets\n",
        "\n",
        "# Load official WMT20 test set\n",
        "wmt_test = datasets.load_dataset('wmt19', 'en-es', split='validation')\n",
        "\n",
        "# Extract sentences\n",
        "test_sources = [ex['translation']['en'] for ex in wmt_test]\n",
        "test_references = [[ex['translation']['es']] for ex in wmt_test]  # List of lists\n",
        "\n",
        "# Translate your sources\n",
        "your_hypotheses = [translate_sentence(encoder, decoder, src, src_vocab, tgt_vocab, device)\n",
        "                   for src in test_sources]\n",
        "\n",
        "# Compute BLEU against official references\n",
        "bleu = sacrebleu.corpus_bleu(your_hypotheses, test_references, tokenize='intl')\n",
        "print(f\"Your model BLEU on WMT20 en-es: {bleu.score:.2f}\")\n",
        "\n",
        "# Compare to published results:\n",
        "# - Google Translate (2023): ~43.5 BLEU\n",
        "# - Modern Transformer (WMT winner): ~45.2 BLEU\n",
        "# - Your Seq2Seq RNN baseline: ~25-32 BLEU (typical)"
      ],
      "metadata": {
        "id": "UzWQvmkin2To"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}