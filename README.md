# NMT-Neural-Machine-Translation-
seq2seq model with attention for English to Spanish translation
This project implements a Sequence-to-Sequence (Seq2Seq) Transformer model from scratch using PyTorch for high-accuracy English-to-Spanish translation. Trained on the OPUS TED2020 corpus, the model utilizes Multi-Head Attention and Teacher Forcing to handle complex linguistic dependencies and morphological nuances. Performance is validated using industry-standard SacreBLEU and chrF metrics, achieving competitive benchmarks against WMT19 standards.
